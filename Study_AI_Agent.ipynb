{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPWzIsV7pJDbnpfNLleUSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emz95/AIagent/blob/main/Study_AI_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6N4WY5Xge-s",
        "outputId": "4200e6aa-b496-4312-c93b-676b9e3ae948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.9)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.7.10)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain-google-genai tavily-python\n",
        "\n",
        "!pip install -U langchain langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Literal, Dict\n",
        "\n",
        "class CurriculumState(TypedDict):\n",
        "    topic: str\n",
        "    plan: List[Dict]\n",
        "    current_week: int\n",
        "    num_weeks: int\n",
        "    completed_lessons: List[str]\n",
        "    quiz_attempts: List[str]\n",
        "    notes: List[str]\n",
        "    resources: List[Dict]\n",
        "    user_feedback: List[str]\n",
        "    phase: Literal[\"start\", \"planning\", \"resources\", \"quiz\", \"leader\", \"end\"]\n",
        "    phase_history: List[str]\n"
      ],
      "metadata": {
        "id": "E1dJF3q5gije"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompts\n",
        "\n",
        "def build_study_plan_prompt(topic, num_weeks):\n",
        "    return f\"\"\"\n",
        "    Create a {num_weeks}-week study plan for the topic: \"{topic}\".\n",
        "    Respond ONLY with a valid JSON array containing {num_weeks} objects.\n",
        "\n",
        "    Each object must have two keys:\n",
        "    - 'week': (an integer from 1 to {num_weeks})\n",
        "    - 'focus': (a short, descriptive string summarizing the learning goal for that week)\n",
        "\n",
        "    Format example:\n",
        "    [{{\"week\": 1, \"focus\": \"Intro to {topic}\"}}, ..., {{\"week\": {num_weeks}, \"focus\": \"Advanced topics in {topic}\"}}]\n",
        "\n",
        "    Do NOT include any extra commentary, markdown, or text outside of the JSON array.\n",
        "    \"\"\".strip()\n",
        "\n",
        "\n",
        "def build_quiz_generation_prompt(topic, current_week, titles):\n",
        "    formatted_titles = \"\\n\".join(f\"- {t}\" for t in titles)\n",
        "    return f\"\"\"\n",
        "    You're an AI tutor generating a short-answer quiz for a student learning about \"{topic}\".\n",
        "    Use the following article titles from Week {current_week} to write **3 open-ended questions** that test true understanding of the concepts.\n",
        "\n",
        "    Guidelines:\n",
        "    - Each question should focus on one concrete concept or technique from the topics.\n",
        "    - Ask about definitions, applications, comparisons, or reasoning.\n",
        "    - Avoid vague questions like \"What do you think...?\" or \"How might...?\"\n",
        "    - No multiple choice. Use only short-answer format.\n",
        "    - Make sure each question has a clearly correct answer.\n",
        "    - Do NOT generate questions that:\n",
        "        - Ask about the meaning of article **titles**\n",
        "        - Infer themes or implications based only on article names\n",
        "        - Require speculation or high-level guessing\n",
        "        - Are vague or abstract\n",
        "\n",
        "    Format your response like this (valid JSON):\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"question\": \"What role do embeddings play in LLMs?\",\n",
        "        \"answer\": \"Embeddings convert text into numerical representations that preserve semantic meaning, allowing LLMs to understand context and relationships between words.\"\n",
        "      }},\n",
        "      ...\n",
        "    ]\n",
        "\n",
        "    Here are the article titles:\n",
        "    {formatted_titles}\n",
        "    \"\"\"\n",
        "\n",
        "def build_grading_prompt(question, expected_answer, student_answer):\n",
        "    return f\"\"\"\n",
        "    You are grading a student's open-ended response to a quiz question.\n",
        "\n",
        "    Question: {question}\n",
        "    Expected Answer: {expected_answer}\n",
        "    Student's Answer: {student_answer}\n",
        "\n",
        "    Instructions:\n",
        "    - Base your judgment only on the student's answer.\n",
        "    - If they wrote things like \"I don't know\", \"no idea\", or left it vague or unrelated, mark it Incorrect.\n",
        "    - Be strict. Only mark it Correct if they clearly show understanding of the key concept.\n",
        "    - Use \"Partially correct\" if they mention related ideas but miss the core.\n",
        "    - Be sure to state what the correct answer is.\n",
        "    - Talk as if you are giving feedback directly to the student.\n",
        "\n",
        "    Reply in **exactly** this format:\n",
        "\n",
        "    Judgment: Correct | Partially correct | Incorrect\n",
        "    Explanation: <Briefly explain why and what the correct answer involves>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def build_answer_question_prompt(topic, question):\n",
        "    return f\"\"\"\n",
        "    You are an AI tutor helping a student learn about \"{topic}\".\n",
        "    The student has asked the following question:\n",
        "\n",
        "    \"{question}\"\n",
        "\n",
        "    Instructions:\n",
        "    - First, determine if the question is clearly related to the topic \"{topic}\".\n",
        "    - If it is NOT related, respond: \"Sorry, I can only help with questions related to {topic} right now.\"\n",
        "    - If it IS related, provide a thoughtful, clear explanation. Use examples or analogies if helpful.\n",
        "    - Keep the tone friendly, encouraging, and easy to understand.\n",
        "\n",
        "    Respond as the tutor, directly to the student.\n",
        "    \"\"\"\n",
        "\n",
        "def build_explanation_prompt(current_week, article_titles):\n",
        "    return f\"\"\"\n",
        "    You are an AI tutor helping a student understand this week's topics.\n",
        "    Based on the following article titles from Week {current_week}, identify the key topics mentioned and explain them in a clear, student-friendly way.\n",
        "\n",
        "    Article Titles:\n",
        "    {chr(10).join(f\"- {title}\" for title in article_titles)}\n",
        "\n",
        "    Provide a structured explanation that covers each topic clearly, as if you are teaching it for the first time.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def build_leader_decision_prompt(state, feedback):\n",
        "    return f\"\"\"\n",
        "    You are a helpful AI learning assistant. Your job is to decide what the student wants to do next\n",
        "    based on their feedback and the current state of the learning session.\n",
        "\n",
        "    Here are the phases you can choose from, with descriptions:\n",
        "\n",
        "    - **planning**: Generate a week-by-week study plan for the selected topic.\n",
        "    - **resources**: Find and present 2–3 curated articles or videos for the current week's focus.\n",
        "    - **explain**: Teach the student the core concepts of this week's topic based on the resources found. Only if student wants to regenerate explanation for multiple concepts.\n",
        "    - **quiz**: Ask 2–3 short-answer questions to check if the student understood this week's material.\n",
        "    - **answer**: Directly answer a specific question the student has asked, if it relates to the topic. Or explain or revisit a concept the student requests explicitly.\n",
        "    - **end**: Wrap up the session if the student is done or expresses no interest in continuing.\n",
        "    - **continue**: The student wants to continue the current week's flow. This means moving from planning → resources → explain → quiz in order.\n",
        "      - Triggered by phrases like: \"continue\", \"go ahead\", \"next\", \"move on\", \"keep going\", etc.\n",
        "      - DO NOT infer the next step — just return \"continue\".\n",
        "      - DO NOT use this if they say \"next week\" or clearly want to skip the current week.\n",
        "\n",
        "    - **next_week**: The student wants to **skip the rest of the current week** and move on to the **next week's content**.\n",
        "      - Triggered by: \"next week\", \"skip this\", \"skip to week 2\", \"start week 2\", etc.\n",
        "\n",
        "    Now decide what action to take. Use the following format:\n",
        "\n",
        "    Thought: <your reasoning>\n",
        "    Action: <one of planning, resources, explain, quiz, answer, continue, next_week, end>\n",
        "    Action Input: <input if needed>\n",
        "\n",
        "    Feedback: {feedback}\n",
        "    Topic: {state.get('topic')}\n",
        "    Notes: {state.get('notes')}\n",
        "    Plan: {state.get('plan')}\n",
        "    Resources: {state.get('resources')}\n",
        "    Phase History: {state.get('phase_history')}\n",
        "    Current Week: {state.get('current_week')}\n",
        "    Completed Lessons: {state.get('completed_lessons')}\n",
        "    Quiz Attempts: {state.get('quiz_attempts')}\n",
        "    \"\"\"\n"
      ],
      "metadata": {
        "id": "XaFm-gS0EwFu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import Tool\n",
        "import os\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-lite-preview-06-17\",\n",
        "    temperature=0.7,\n",
        "    google_api_key=userdata.get(\"GENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "search_tool = TavilySearchResults(\n",
        "    tavily_api_key=userdata.get(\"TAVILY_API_KEY\"))\n",
        "\n",
        "def generate_study_plan(state):\n",
        "    prompt = build_study_plan_prompt(state['topic'], state['num_weeks'])\n",
        "    output = llm.invoke(prompt).content\n",
        "    print(\"--- Raw LLM Output for Study Plan ---\")\n",
        "    print(output)  # Print the raw output\n",
        "    try:\n",
        "        # Attempt to parse the JSON\n",
        "        return json.loads(output)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON: {e}\")\n",
        "        print(\"Attempting to extract JSON from output...\")\n",
        "        try:\n",
        "            # Look for the first '[' and last ']' to try and isolate the JSON array\n",
        "            start_index = output.find('[')\n",
        "            end_index = output.rfind(']')\n",
        "            if start_index != -1 and end_index != -1 and end_index > start_index:\n",
        "                json_string = output[start_index : end_index + 1]\n",
        "                return json.loads(json_string)\n",
        "            else:\n",
        "                print(\"Could not find valid JSON array in the output.\")\n",
        "                return []  # Return empty plan if extraction fails\n",
        "        except Exception as ex:\n",
        "            print(f\"Extraction attempt failed: {ex}\")\n",
        "            return []  # Return empty plan if extraction fai\n",
        "\n",
        "\n",
        "def reset_state(state):\n",
        "    state['resources'] = []\n",
        "    state['quiz_attempts'] = []\n",
        "    state['notes'] = []\n",
        "    state['completed_lessons'] = []\n",
        "    state['current_week'] = 1"
      ],
      "metadata": {
        "id": "a9o2Iuihg0J4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "def start_node(state):\n",
        "    state['topic'] = input(\"What do you want to learn? \").strip()\n",
        "\n",
        "    weeks_input = input(\"Over how many weeks would you like to study it? (press Enter to use 3 weeks): \").strip()\n",
        "    try:\n",
        "        num_weeks = int(weeks_input)\n",
        "        if num_weeks <= 0:\n",
        "            raise ValueError\n",
        "    except ValueError:\n",
        "        print(\"Using default: 3 weeks.\")\n",
        "        num_weeks = 3\n",
        "\n",
        "    state['num_weeks'] = num_weeks\n",
        "    state['phase_history'].append('start')\n",
        "    state['phase'] = 'planning'\n",
        "    print(f\"--- Start Node returning. Next phase: {state['phase']} ---\")\n",
        "    return state\n",
        "\n",
        "def planning_node(state):\n",
        "    print(\"--- Study Plan ---\")\n",
        "    state['plan'] = generate_study_plan(state)\n",
        "    # check if plan generated\n",
        "    if state['plan']:\n",
        "        for week in state['plan']:\n",
        "            # Ensure week and focus keys exist before printing\n",
        "            if 'week' in week and 'focus' in week:\n",
        "                 print(f\"Week {week['week']}: {week['focus']}\")\n",
        "            else:\n",
        "                print(\"Warning: Invalid week structure in plan.\")\n",
        "\n",
        "        # reset if new plan generated\n",
        "        reset_state(state)\n",
        "\n",
        "        #add to history\n",
        "        state['phase_history'].append('planning')\n",
        "        state['phase'] = 'leader'\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Failed to generate a valid study plan.\")\n",
        "        state['phase'] = 'leader' # Return to leader to handle the failure or try again\n",
        "\n",
        "    print(f\"--- Planning Node returning. Next phase: {state['phase']} ---\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def resource_node(state):\n",
        "    print(\"--- Finding Resources ---\")\n",
        "    current_week = state.get(\"current_week\", 1)\n",
        "    if not state[\"plan\"]:\n",
        "        print(\"No study plan found.\")\n",
        "        state[\"phase\"] = \"leader\"\n",
        "        return state\n",
        "\n",
        "    week_info = next((week for week in state[\"plan\"] if week[\"week\"] == current_week), None)\n",
        "    if not week_info or \"focus\" not in week_info:\n",
        "        print(f\"No valid focus found for Week {current_week}.\")\n",
        "        state[\"phase\"] = \"leader\"\n",
        "        return state\n",
        "\n",
        "    focus = week_info[\"focus\"]\n",
        "    print(f\"Resources for Week {current_week}: {focus}\")\n",
        "    results = search_tool.invoke(focus)  # assume returns list of {title, url}\n",
        "\n",
        "    top_links = results[:3]\n",
        "    for r in top_links:\n",
        "        print(f\"- {r['title']} ({r['url']})\")\n",
        "\n",
        "    # Ensure resources is a dict by week\n",
        "    if not isinstance(state.get(\"resources\"), dict):\n",
        "        state[\"resources\"] = {}\n",
        "\n",
        "    state[\"resources\"][current_week] = top_links\n",
        "\n",
        "    # Phase tracking\n",
        "    state['phase_history'].append('resources')\n",
        "    state[\"phase\"] = \"leader\"\n",
        "    print(f\"--- Resource Node returning. Next phase: {state['phase']} ---\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def quiz_node(state):\n",
        "    import ast\n",
        "\n",
        "    print(\"--- Quiz Time! ---\")\n",
        "    current_week = state.get(\"current_week\", 1)\n",
        "    topic = state.get(\"topic\", \"LLMs\")\n",
        "\n",
        "    week_resources = state[\"resources\"].get(current_week, [])\n",
        "    titles = [r[\"title\"] for r in week_resources if \"title\" in r]\n",
        "\n",
        "    prompt = build_quiz_generation_prompt(topic, current_week, titles)\n",
        "\n",
        "    try:\n",
        "        raw_response = llm.invoke(prompt).content\n",
        "        clean_json = re.sub(r\"```json|```\", \"\", raw_response).strip()\n",
        "        questions = json.loads(clean_json)\n",
        "    except Exception as e:\n",
        "        print(\"Could not generate quiz questions:\", e)\n",
        "        print(\"--- Raw LLM Output ---\")\n",
        "        print(raw_response)\n",
        "        state[\"phase\"] = \"leader\"\n",
        "        return state\n",
        "\n",
        "    correct = 0\n",
        "    for idx, q in enumerate(questions):\n",
        "        print(f\"\\nQuestion {idx + 1}: {q['question']}\")\n",
        "        user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "        # Evaluate with LLM\n",
        "        grading_prompt = build_grading_prompt(q['question'], q['answer'], user_answer)\n",
        "\n",
        "        result = llm.invoke(grading_prompt).content\n",
        "        lines = result.splitlines()\n",
        "\n",
        "        judgment_line = next((l for l in lines if l.lower().startswith(\"judgment:\")), \"\")\n",
        "        explanation_line = next((l for l in lines if l.lower().startswith(\"explanation:\")), \"\")\n",
        "\n",
        "        judgment = judgment_line.split(\":\", 1)[1].strip().lower() if \":\" in judgment_line else \"unknown\"\n",
        "        explanation = explanation_line.split(\":\", 1)[1].strip() if \":\" in explanation_line else result\n",
        "\n",
        "        if judgment == \"correct\":\n",
        "            print(\"Correct!\")\n",
        "            correct += 1\n",
        "        elif judgment == \"partially correct\":\n",
        "            print(\"Partially correct.\")\n",
        "            print(explanation)\n",
        "        else:\n",
        "            print(\"Incorrect.\")\n",
        "            print(explanation)\n",
        "\n",
        "    print(f\"\\You got {correct} fully correct out of {len(questions)}.\")\n",
        "    state[\"quiz_attempts\"].append(topic)\n",
        "\n",
        "\n",
        "    state['phase_history'].append('quiz')\n",
        "    state[\"phase\"] = \"leader\"\n",
        "\n",
        "    print(f\"--- Quiz Node returning. Next phase: {state['phase']} ---\")\n",
        "    return state\n",
        "\n",
        "def explain_node(state):\n",
        "    current_week = state.get('current_week', 1)\n",
        "\n",
        "    # Get resources for the current week\n",
        "    week_resources = state['resources'].get(current_week, [])\n",
        "    article_titles = [r.get('title', '') for r in week_resources if r.get('title')]\n",
        "\n",
        "    if not article_titles:\n",
        "        print(\"No article titles found for this week.\")\n",
        "        state['phase'] = 'leader'\n",
        "        return state\n",
        "\n",
        "    prompt = build_explanation_prompt(current_week, article_titles)\n",
        "\n",
        "    explanation = llm.invoke(prompt).content\n",
        "\n",
        "    # Show the explanation\n",
        "    print(\"--- AI Explanation Based on Article Titles ---\")\n",
        "    print(explanation)\n",
        "\n",
        "    # Log that this week was explained\n",
        "    state['notes'].append(f\"Week {current_week} explained based on article titles\")\n",
        "\n",
        "    # Track phase\n",
        "    state['phase_history'].append('explain')\n",
        "\n",
        "    state['phase'] = 'leader'\n",
        "    print(f\"--- Explain Node returning. Next phase: {state['phase']} ---\")\n",
        "\n",
        "    return state\n",
        "\n",
        "def answer_node(state):\n",
        "    question = state['user_feedback'][-1]\n",
        "    topic = state['topic']\n",
        "    prompt = build_answer_question_prompt(topic, question)\n",
        "    ai_answer = llm.invoke(prompt).content\n",
        "    print(ai_answer)\n",
        "    state['phase'] = 'leader'\n",
        "    print(f\"--- Answer Node returning. Next phase: {state['phase']} ---\")\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "def leader_node(state):\n",
        "    # Determine the next phase hint for the prompt (for the 'continue' option)\n",
        "\n",
        "    last_phase = state['phase_history'][-1] if state['phase_history'] else None\n",
        "\n",
        "    if last_phase == 'planning':\n",
        "        next_phase_hint = 'resources'\n",
        "    elif last_phase == 'resources':\n",
        "        next_phase_hint = 'explain'\n",
        "    elif last_phase == 'explain':\n",
        "        next_phase_hint = 'quiz'\n",
        "    elif last_phase == 'quiz':\n",
        "        if state['current_week'] <= state['num_weeks']:\n",
        "            next_phase_hint = 'resources'\n",
        "        else:\n",
        "            next_phase_hint = 'end'\n",
        "    else:\n",
        "        next_phase_hint = 'planning'\n",
        "\n",
        "\n",
        "    # 1) Collect user feedback with the next phase hint\n",
        "    feedback = input(f\"What would you like to do next (or any thoughts)? Type 'continue' to proceed sequentially to the {next_phase_hint} phase, or make a specific request: \")\n",
        "    state['user_feedback'].append(feedback)\n",
        "\n",
        "\n",
        "    prompt = build_leader_decision_prompt(state, feedback)\n",
        "    decision = llm.invoke(prompt).content\n",
        "    print(\"--- Agent Decision ---\")\n",
        "    print(decision)\n",
        "\n",
        "    # 5) Parse LLM output\n",
        "    action = None\n",
        "    action_input = None\n",
        "    # Split lines and find Action and Action Input\n",
        "    for line in decision.splitlines():\n",
        "        if line.lower().startswith('action:'):\n",
        "            action = line.split(':',1)[1].strip().lower()\n",
        "        elif line.lower().startswith('action input:'):\n",
        "            action_input = line.split(':',1)[1].strip()\n",
        "\n",
        "    # 6) Dispatch based on action\n",
        "    if action == 'continue':\n",
        "        # move to the next logical phase (already determined for the hint)\n",
        "        if last_phase == 'quiz' and state['current_week'] < state['num_weeks']:\n",
        "          state['current_week'] += 1\n",
        "          print(f\"Moving to week {state['current_week']}\")\n",
        "        state['phase'] = next_phase_hint\n",
        "        print(f\"--- Leader Node (Continue) returning. Next phase: {state['phase']} ---\")\n",
        "        return state\n",
        "    if action == 'planning':\n",
        "        state['phase'] = 'planning'\n",
        "    elif action == 'resources':\n",
        "        state['phase'] = 'resources' # Set phase to 'resources'\n",
        "    elif action == 'quiz':\n",
        "        state['phase'] = 'quiz' # Set phase to 'quiz'\n",
        "    elif action == 'explain':\n",
        "        state['phase'] = 'explain' # Set phase to 'explain'\n",
        "    elif action == 'answer':\n",
        "        state['phase'] = 'answer' # Set phase to 'answer'\n",
        "    elif action == 'next_week':\n",
        "      if state['current_week'] < len(state['plan']):\n",
        "          state['current_week'] += 1\n",
        "          print(f\"Moving to Week {state['current_week']}\")\n",
        "          state['phase'] = 'resources'\n",
        "      else:\n",
        "          print(\"You've already completed all available weeks.\")\n",
        "          state['phase'] = 'end'\n",
        "    elif action == 'end':\n",
        "        state['phase'] = 'end' # Set phase to 'end'\n",
        "    else:\n",
        "        print(f\"Unrecognized action: {action}. Returning to leader.\")\n",
        "        state['phase'] = 'leader' # Return to leader for unrecognized action\n",
        "\n",
        "    print(f\"--- Leader Node (Agent) returning. Next phase: {state['phase']} ---\") # Print current phase\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def end_node(state):\n",
        "    print(\"Session complete. See you next time!\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "-7RkjLrYo5bq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List, Literal, Dict\n",
        "\n",
        "graph = StateGraph(CurriculumState)\n",
        "\n",
        "# Register each node (phase) with the graph\n",
        "graph.add_node('start', start_node)\n",
        "graph.add_node('planning', planning_node)\n",
        "graph.add_node('resources_node', resource_node)\n",
        "graph.add_node('explain', explain_node)\n",
        "graph.add_node('answer', answer_node)\n",
        "graph.add_node('quiz', quiz_node)\n",
        "graph.add_node('leader', leader_node)\n",
        "graph.add_node('end', end_node)\n",
        "\n",
        "# Set the entry point\n",
        "graph.set_entry_point('start')\n",
        "\n",
        "# Define valid transitions\n",
        "graph.add_edge('start', 'planning')\n",
        "graph.add_edge('planning', 'leader')\n",
        "for src in ['resources_node', 'quiz', 'answer', 'explain']:\n",
        "    graph.add_edge(src, 'leader')\n",
        "\n",
        "# Use a conditional edge from leader to route based on the 'phase' in the state\n",
        "# Explicitly add a transition from 'leader' to 'leader' for self-loop\n",
        "graph.add_conditional_edges(\n",
        "    'leader',\n",
        "    # The condition is a function that takes the state and returns the next node name\n",
        "    lambda state: state['phase'],\n",
        "    {\n",
        "        \"planning\": \"planning\",\n",
        "        \"resources\": \"resources_node\", # Note: The phase name in state is 'resources', but the node name is 'resources_node'\n",
        "        \"quiz\": \"quiz\",\n",
        "        \"answer\": \"answer\",\n",
        "        \"explain\": \"explain\",\n",
        "        \"leader\": \"leader\", # Explicitly define self-loop for phase 'leader'\n",
        "        \"end\": END # Use END for the final state\n",
        "    }\n",
        ")\n",
        "\n",
        "# Final end state - already handled by conditional edge to END\n",
        "\n",
        "# Compile into a runnable app\n",
        "app = graph.compile()\n",
        "\n",
        "# Initialize and run\n",
        "initial_state = {\n",
        "    'topic': '',\n",
        "    'plan': [],\n",
        "    'current_week': 0,\n",
        "    'num_weeks': 0,\n",
        "    'completed_lessons': [],\n",
        "    'quiz_attempts': [],\n",
        "    'notes': [],\n",
        "    'resources': [],\n",
        "    'user_feedback': [],\n",
        "    'phase': 'start', # Initial phase\n",
        "    'phase_history': [] # Initialize phase history\n",
        "}\n",
        "\n",
        "# The graph execution will start here and proceed through the defined nodes and transitions\n",
        "app.invoke(initial_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5PpDz7JpJUT",
        "outputId": "1f7b2d08-97d9-43d5-b20f-9e0d2e87be08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you want to learn? llms\n",
            "Over how many weeks would you like to study it? (press Enter to use 3 weeks): 5\n",
            "--- Start Node returning. Next phase: planning ---\n",
            "--- Study Plan ---\n",
            "--- Raw LLM Output for Study Plan ---\n",
            "[\n",
            "  {\n",
            "    \"week\": 1,\n",
            "    \"focus\": \"Foundational Concepts: What are LLMs, their history, and basic architectures (e.g., Transformers).\"\n",
            "  },\n",
            "  {\n",
            "    \"week\": 2,\n",
            "    \"focus\": \"LLM Training & Fine-tuning: Understanding pre-training, fine-tuning techniques, and data requirements.\"\n",
            "  },\n",
            "  {\n",
            "    \"week\": 3,\n",
            "    \"focus\": \"LLM Applications & Capabilities: Exploring common use cases like text generation, translation, summarization, and question answering.\"\n",
            "  },\n",
            "  {\n",
            "    \"week\": 4,\n",
            "    \"focus\": \"Prompt Engineering & Interaction: Learning how to effectively communicate with LLMs and craft optimal prompts.\"\n",
            "  },\n",
            "  {\n",
            "    \"week\": 5,\n",
            "    \"focus\": \"Ethical Considerations & Future Trends: Discussing bias, safety, responsible deployment, and emerging research in LLMs.\"\n",
            "  }\n",
            "]\n",
            "Week 1: Foundational Concepts: What are LLMs, their history, and basic architectures (e.g., Transformers).\n",
            "Week 2: LLM Training & Fine-tuning: Understanding pre-training, fine-tuning techniques, and data requirements.\n",
            "Week 3: LLM Applications & Capabilities: Exploring common use cases like text generation, translation, summarization, and question answering.\n",
            "Week 4: Prompt Engineering & Interaction: Learning how to effectively communicate with LLMs and craft optimal prompts.\n",
            "Week 5: Ethical Considerations & Future Trends: Discussing bias, safety, responsible deployment, and emerging research in LLMs.\n",
            "--- Planning Node returning. Next phase: leader ---\n",
            "What would you like to do next (or any thoughts)? Type 'continue' to proceed sequentially to the resources phase, or make a specific request: continue\n",
            "--- Agent Decision ---\n",
            "Thought: The student has provided \"continue\" as feedback. The current phase is 'planning' and the phase history shows the user has just completed planning. The next logical step in the learning flow is to get resources for the current week.\n",
            "Action: resources\n",
            "Action Input: Week 1: Foundational Concepts: What are LLMs, their history, and basic architectures (e.g., Transformers).\n",
            "--- Leader Node (Agent) returning. Next phase: resources ---\n",
            "--- Finding Resources ---\n",
            "Resources for Week 1: Foundational Concepts: What are LLMs, their history, and basic architectures (e.g., Transformers).\n",
            "- Introduction to Large Language Models and the Transformer ... (https://rpradeepmenon.medium.com/introduction-to-large-language-models-and-the-transformer-architecture-534408ed7e61)\n",
            "- The history, timeline, and future of LLMs - Toloka (https://toloka.ai/blog/history-of-llms/)\n",
            "- What is LLM? - Large Language Models Explained - AWS (https://aws.amazon.com/what-is/large-language-model/)\n",
            "--- Resource Node returning. Next phase: leader ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2A9Brsn9LRZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}